{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dd1489",
   "metadata": {},
   "source": [
    "# IMPORTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3156ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.10.4 64-bit' requires notebook and jupyter package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stopwords = stopwords.words('english')\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from nltk.translate import bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea943abe",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95e7ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(base, response):\n",
    "    sentences = [base, response]\n",
    "    def clean_string(text):\n",
    "        text = ''.join([word for word in text if word not in string.punctuation])\n",
    "        text = text.lower()\n",
    "        text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "        return text\n",
    "    cleaned = list(map(clean_string, sentences))\n",
    "    vectorizer = CountVectorizer().fit_transform(cleaned)\n",
    "    vectors = vectorizer.toarray()\n",
    "    csim = cosine_similarity(vectors)\n",
    "    def cosine_sim_vectors(vec1, vec2):\n",
    "        vec1 = vec1.reshape(1, -1)\n",
    "        vec2 = vec2.reshape(1, -1)\n",
    "        return cosine_similarity(vec1, vec2)[0][0]\n",
    "    return (cosine_sim_vectors(vectors[0], vectors[1]))\n",
    "def bertMethod1(base,response):\n",
    "    sen = [\n",
    "        base,response\n",
    "    ]\n",
    "    # from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    sen_embeddings = model.encode(sen)\n",
    "#     print([sen_embeddings[0]])\n",
    "    #let's calculate cosine similarity for sentence 0:\n",
    "    return(cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        sen_embeddings[1:]\n",
    "    ))\n",
    "def newMethod1(base,response):\n",
    "    sen = [\n",
    "        base,response\n",
    "    ]\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    sen_embeddings = model.encode(sen)\n",
    "#     print([sen_embeddings[0]])\n",
    "    #let's calculate cosine similarity for sentence 0:\n",
    "    return(cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        sen_embeddings[1:]\n",
    "    ))\n",
    "def newMethod2(base,response):\n",
    "    sen = [\n",
    "        base,response\n",
    "    ]\n",
    "    model = SentenceTransformer('all-distilroberta-v1')\n",
    "    sen_embeddings = model.encode(sen)\n",
    "#     print([sen_embeddings[0]])\n",
    "    #let's calculate cosine similarity for sentence 0:\n",
    "    return(cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        sen_embeddings[1:]\n",
    "    ))\n",
    "def newMethod3(base,response):\n",
    "    sen = [\n",
    "        base,response\n",
    "    ]\n",
    "    model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "    sen_embeddings = model.encode(sen)\n",
    "#     print([sen_embeddings[0]])\n",
    "    #let's calculate cosine similarity for sentence 0:\n",
    "    return(cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        sen_embeddings[1:]\n",
    "    ))\n",
    "def newMethod4(base,response):\n",
    "    sen = [\n",
    "        base,response\n",
    "    ]\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    sen_embeddings = model.encode(sen)\n",
    "#     print([sen_embeddings[0]])\n",
    "    #let's calculate cosine similarity for sentence 0:\n",
    "    return(cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        sen_embeddings[1:]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc389139",
   "metadata": {},
   "source": [
    "# INTEGRATED SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cae97f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_value_of_bert_and_newMethod1(B,N,numberOfBaseWords,numberOfResponseWords):\n",
    "    difference=numberOfBaseWords-numberOfResponseWords\n",
    "    if(abs(difference)>=(0.55*numberOfBaseWords)):\n",
    "        return 0.6*min(B,N)+0.4*max(B,N)\n",
    "    else:\n",
    "        return 0.6*N+0.4*B\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ec34b4",
   "metadata": {},
   "source": [
    "# EXPORTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdeee471",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_integrated_results=[]\n",
    "list_of_bert_results=[]\n",
    "list_of_newMethod1_results=[]\n",
    "list_of_noOfBaseWords=[]\n",
    "list_of_noOfResponseWords=[]\n",
    "\n",
    "def show_result():\n",
    "    for i in range(1,41):\n",
    "        test_case=\"Test Number-\"+str(i)\n",
    "        b=\"base\"+str(i)+\".txt\"\n",
    "        r=\"trail_\"+str(i)+\".txt\"\n",
    "        with open(b, encoding = \"UTF-8\") as file:\n",
    "            base = file.read()\n",
    "        with open(r, encoding = \"UTF-8\") as file:\n",
    "            response = file.read()\n",
    "        cosinesim_result=(cosineSimilarity(base,response))*100\n",
    "        bertmethod1_result=(bertMethod1(base,response)[0][0])*100\n",
    "        newmethod1_result = (newMethod1(base,response)[0][0]) * 100\n",
    "#         newmethod2_result = (newMethod2(base, response)[0][0]) * 100\n",
    "#         newmethod3_result = (newMethod3(base, response)[0][0]) * 100\n",
    "        # newmethod4_result = (test.newMethod4(base, response)[0][0]) * 100\n",
    "        def BaseWordCount(base):\n",
    "            list_base = base.split(\" \")\n",
    "            return (len(list_base))\n",
    "        no_of_base_words=BaseWordCount(base)\n",
    "        def ResponseWordCount(response):\n",
    "            list_response = response.split(\" \")\n",
    "            return (len(list_response))\n",
    "        no_of_response_words=ResponseWordCount(response)\n",
    "        \n",
    "        integrated_result= integrated_value_of_bert_and_newMethod1(bertmethod1_result,newmethod1_result,no_of_base_words,no_of_response_words)\n",
    "        outfile=open('allData.txt', 'a')\n",
    "        outfile.write(test_case)\n",
    "        outfile.write(\"\\nNumber Of Base Words: \"+str(no_of_base_words)+\"\\n\")\n",
    "        outfile.write(\"Number Of Response Words: \"+str(no_of_response_words)+\"\\n\")\n",
    "        outfile.write(\"Base: \"+base+\"\\n\")\n",
    "        outfile.write(\"Response: \"+response+\"\\n\")\n",
    "        outfile.write(\"Cosine Similarity Result: \"+str(cosinesim_result)+\"\\n\")\n",
    "        outfile.write(\"BERT Similarity Result: \"+str(bertmethod1_result)+\"\\n\")\n",
    "        outfile.write(\"newMethod1 Similarity Result: \" + str(newmethod1_result) + \"\\n\")\n",
    "        outfile.write(\"INTEGRATED RESULT: \"+str(integrated_result)+\"\\n\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        list_of_integrated_results.append(integrated_result)\n",
    "        list_of_bert_results.append(bertmethod1_result)\n",
    "        list_of_newMethod1_results.append(newmethod1_result)\n",
    "        list_of_noOfBaseWords.append(no_of_base_words)\n",
    "        list_of_noOfResponseWords.append(no_of_response_words)\n",
    "        \n",
    "        \n",
    "             \n",
    "        \n",
    "        \n",
    "#         outfile.write(\"newMethod2 Similarity Result: \" + str(newmethod2_result) + \"\\n\")\n",
    "#         outfile.write(\"newMethod3 Similarity Result: \" + str(newmethod3_result) + \"\\n\\n\\n\")\n",
    "        # outfile.write(\"newMethod4 Similarity Result: \" + str(newmethod4_result) + \"\\n\\n\\n\")\n",
    "        outfile.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "def delete_result():\n",
    "    outfile = open('allData.txt', 'w')\n",
    "    outfile.write(\"\")\n",
    "    outfile.write(\"\")\n",
    "    outfile.close()\n",
    "def exportToExcel():\n",
    "    book=openpyxl.load_workbook('allData.xlsx')\n",
    "    sheet=book['Sheet2']\n",
    "    sheet.delete_rows(1,sheet.max_row)\n",
    "    data=pd.DataFrame({'Integrated Result':list_of_integrated_results,'Bert Result':list_of_bert_results,'NewMethod Result':list_of_newMethod1_results,'No of Base Words':list_of_noOfBaseWords,'No of Response words':list_of_noOfResponseWords})\n",
    "    datatoexcel=pd.ExcelWriter(\"allData.xlsx\",engine='xlsxwriter')\n",
    "    data.to_excel(datatoexcel,sheet_name='Sheet2')\n",
    "    datatoexcel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84fda374",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bd167c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbabc3a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exportToExcel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b762b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85d3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
